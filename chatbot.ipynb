{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNswfR09gsZ8lZE0Y2O+pjW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishgeorge1811/nlpchatbot/blob/master/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AqLh-2pITF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import random\n",
        "import string # to process standard python strings\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVENtdE0ITNW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7a61566d-bc64-40fd-aadd-449102d1282e"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('popular', quiet=True) # for downloading packages"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASSPezAeJTH9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "46e9154a-6a6b-4a2b-d61c-c80a4004bf3e"
      },
      "source": [
        "nltk.download('punkt') # first-time use only\n",
        "nltk.download('wordnet') # first-time use only"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeK1TcXyrWJ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "3b4f1619-48c6-45e1-bbbd-6facd2b7b0ef"
      },
      "source": [
        "text=\"NLP or Natural Language Processing  is a field that is concerned to describe the ability of a computer to understand, analyze, manipulate, and potentially generate human language. Financial Industries are providing good service to customers for financial consultation by creating chatbots that reply answers promptly to the questions of customers in a human manner. It is estimated that the Healthcare Industry contains 80 % of the data related to the patients are in an unstructured format.To conduct research and development on drugs efficiently, improve treatment standards, and validating the outcomes of treatments given to the patients simply and as automatically as possible NLP plays a vital role. Natural language processing is a magical looking glass through which the digital marketers can be able to observe what the customers wish to purchase. And brand perception is done through social listening by analyzing the large scale of text data related to the customers’ details. Tokenization is a process of splitting a paragraph, sentence, phrase into small units, and each unit is called as tokens. Depending on the selection, the tokens can be a sentence, word, etc. Punctuations are marks like a full stop, comma, colon, special characters, etc to make clear the sentence meaningfully in writing sentences. Stemming is a process of reducing the inflective words to their root word or word stem. By using stemming algorithms it explicitly correlates words with similar meaning.  Lemmatization Algorithm is the same as the Stemming Algorithm, the only difference is that it will reduce the reflective words to meaningful words.A count vectorizer is a collection of text documents to a vector. It enables the pre-processing of text data to generate the vector representation. This functionality makes it a highly flexible feature representation module for text.  TF-IDF as, a measure of the originality of a word by comparing the number of times a word appears in a document with the number of documents the words appear in.  \"\n",
        "#convert the text to small letters\n",
        "#one line code\n",
        "text = "
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'nlp or natural language processing  is a field that is concerned to describe the ability of a computer to understand, analyze, manipulate, and potentially generate human language. financial industries are providing good service to customers for financial consultation by creating chatbots that reply answers promptly to the questions of customers in a human manner. it is estimated that the healthcare industry contains 80 % of the data related to the patients are in an unstructured format.to conduct research and development on drugs efficiently, improve treatment standards, and validating the outcomes of treatments given to the patients simply and as automatically as possible nlp plays a vital role. natural language processing is a magical looking glass through which the digital marketers can be able to observe what the customers wish to purchase. and brand perception is done through social listening by analyzing the large scale of text data related to the customers’ details. tokenization is a process of splitting a paragraph, sentence, phrase into small units, and each unit is called as tokens. depending on the selection, the tokens can be a sentence, word, etc. punctuations are marks like a full stop, comma, colon, special characters, etc to make clear the sentence meaningfully in writing sentences. stemming is a process of reducing the inflective words to their root word or word stem. by using stemming algorithms it explicitly correlates words with similar meaning.  lemmatization algorithm is the same as the stemming algorithm, the only difference is that it will reduce the reflective words to meaningful words.a count vectorizer is a collection of text documents to a vector. it enables the pre-processing of text data to generate the vector representation. this functionality makes it a highly flexible feature representation module for text.  tf-idf as, a measure of the originality of a word by comparing the number of times a word appears in a document with the number of documents the words appear in.  '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16S0zfIsITP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converts the text to list of sentences\n",
        "#one line of code\n",
        "sent_tokens = \n",
        "# converts to list of words\n",
        "#one line of code\n",
        "word_tokens = "
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQIYZaLWITXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qHpVP8JITZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#assign the greeting input as 'hey','hello','wassup','hi','sup'\n",
        "\n",
        "GREETING_INPUTS = ()\n",
        "#assign the greeting responses as 'hi','hello','I am glad! You are talking to me','hey'\n",
        "GREETING_RESPONSES = []\n",
        "def greeting(sentence):\n",
        " \n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDs7oz8TITcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    sent_tokens.append(user_response)\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf==0):\n",
        "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sent_tokens[idx]\n",
        "        return robo_response"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrYiqBmMITfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flag=True\n",
        "#make the robot started saying as 'hi,I am NLP Prototype ROBO ready to answer your enquires about NLP.if you want to exit,type bye!' \n",
        "print()\n",
        "while(flag==True):\n",
        "    user_response = input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='bye'):\n",
        "        if(user_response=='thanks' or user_response=='thank you' ):\n",
        "            flag=False\n",
        "            print(\"ROBO: You are welcome..\")\n",
        "        else:\n",
        "            if(greeting(user_response)!=None):\n",
        "                print(\"ROBO: \"+greeting(user_response))\n",
        "            else:\n",
        "                print(\"ROBO: \",end=\"\")\n",
        "                print(response(user_response))\n",
        "                sent_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"ROBO: Bye! take care..\")\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6vwZTK1brCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QUESTIONS TO ASK THE ROBO\n",
        "1. What is NLP\n",
        "2.What is tokenization\n",
        "3.how nlp is helpful in healthcare\n",
        "4.what is tfidf\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}